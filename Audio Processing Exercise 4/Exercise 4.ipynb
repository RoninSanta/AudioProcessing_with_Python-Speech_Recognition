{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a161d922",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shenf\\anaconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Download & Install deepspeech module \n",
    "########## RUN THIS TO IMPORT libraries ################\n",
    "#!pip install deepspeech // If doing in lab environment\n",
    "#!pip install librosa // If doing in lab environment\n",
    "# jiwer is a package to approximate the Word Error Rate (WER)\n",
    "# !pip install jiwer\n",
    "# !pip install noisereduce\n",
    "# !pip install pydub\n",
    "####################################################\n",
    "#Import DeepSpeech Libraries\n",
    "from deepspeech import Model, version\n",
    "from jiwer import wer\n",
    "%matplotlib inline\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "# Widgets for dropdown language selector\n",
    "import ipywidgets\n",
    "from scipy.io import wavfile\n",
    "from thinkdsp import read_wave\n",
    "import thinkdsp\n",
    "import noisereduce as nr\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d338bc45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select folder with audio files\n",
    "language_EN = \"./Ex4_audio_files/EN\"\n",
    "language_ES = \"./Ex4_audio_files/ES\"\n",
    "language_IT = \"./Ex4_audio_files/IT\"\n",
    "# Select folder with noise reduced\n",
    "NoiseReduced_ES = \"./Ex4_audio_files/ES/Noise_reduced/Filtered\"\n",
    "Silenced_IT = \"./Ex4_audio_files/IT/SilenceAdded\"\n",
    "# Assign all files as a variable\n",
    "audio_fileEN = glob(language_EN+'/*.wav')\n",
    "audio_fileES = glob(language_ES+'/*.wav')\n",
    "audio_fileIT = glob(language_IT+'/*.wav')\n",
    "# Assign noise reduced as variable \n",
    "Filtered_ES = glob(NoiseReduced_ES+'/*.wav')\n",
    "NewAudio_IT = glob(Silenced_IT+'/*.wav')\n",
    "#Number of audio files in EN folder\n",
    "len(audio_fileEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ec9a1",
   "metadata": {},
   "source": [
    "### [Language Selector] - Choose from Dropdown box below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60a218a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3972e4dc1249470d9f6f4c812d02e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Language Select:', options=(('None', 0), ('English', 1), ('Spanishâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Language Selector\n",
    "Lang_dropDown = ipywidgets.Dropdown(options=[('None', 0), ('English', 1), ('Spanish', 2), ('Italian', 3)],\n",
    "                                value=0,\n",
    "                                description='Language Select:',\n",
    "                                disabled=False)\n",
    "def SelectLanguage(state): \n",
    "    if state == 1:\n",
    "        print(\"English Language Selected. Please wait for loading...\")\n",
    "        English()\n",
    "        display(df)\n",
    "    if state == 2:\n",
    "        print(\"Spanish Language Selected. Please wait for loading...\")\n",
    "        Spanish()\n",
    "        display(df)\n",
    "    if state == 3:\n",
    "        print(\"Italian Language Selected. Please wait for loading...\")\n",
    "        Italian()\n",
    "        display(df)\n",
    "ipywidgets.interact(SelectLanguage, state=Lang_dropDown );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373632b1",
   "metadata": {},
   "source": [
    "### English Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78dd042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def English():\n",
    "    scorer = \"Models/deepspeech-0.9.3-models.scorer\"\n",
    "    model = \"Models/deepspeech-0.9.3-models.pbmm\"\n",
    "    result = []\n",
    "    WER = []\n",
    "    Total = []\n",
    "    \n",
    "    ds = Model(model)\n",
    "    ds.enableExternalScorer(scorer)\n",
    "    desired_sample_rate = ds.sampleRate()\n",
    "    # For Loop to iterate every wav file \n",
    "    for i in range(0,len(audio_fileEN)):\n",
    "        #Get Filename\n",
    "        filepath = audio_fileEN[i]\n",
    "        filename = os.path.basename(filepath)\n",
    "        print(filename)\n",
    "        \n",
    "        audio = lr.load(audio_fileEN[i], sr=desired_sample_rate)[0]\n",
    "        audio = (audio * 32767).astype(np.int16)  # scale from -1 to 1 to +/-32767\n",
    "        res = ds.stt(audio)\n",
    "        result.append(res)\n",
    "    audioFiles = ['checkin.wav','parents.wav','suitcase.wav', 'what_time.wav', \n",
    "                  'where.wav','your_sentence1.wav','your_sentence2.wav']\n",
    "    transcription = ['where is the checkin desk','i have lost my parents','please i have lost my suitcase',\n",
    "                     'what time is my plane','where are the restaurants and shops',\n",
    "                     'this is my first sentence', 'this is my second sentence']\n",
    "    #Loop to compare each element in result with transcription list\n",
    "    for i in range(0, len(result)):\n",
    "        #Use wer() to find error rate\n",
    "        error = wer(result[i],transcription[i])\n",
    "        #Convert into percentage\n",
    "        percentage = str(round(error*100)) + '%'\n",
    "        avg = round(error*100)\n",
    "        #Print percentage for debugging\n",
    "        #print(percentage)\n",
    "        WER.append(percentage)\n",
    "        #Get Total error rate\n",
    "        Total.append(avg)\n",
    "        #Print comparison strings\n",
    "        #print(result[i],transcription[i])\n",
    "    # Creating an average WER\n",
    "    Sum = sum(Total)\n",
    "    AvgWER = str(round((Sum / len(Total)), 2))  + '%'\n",
    "    print(\"The Average WER is: \"+ AvgWER)\n",
    "    #Global variable to call it outside of function\n",
    "    global df\n",
    "    # Calling DataFrame constructor on list\n",
    "    df = pd.DataFrame(list(zip(audioFiles, transcription, result, WER)),\n",
    "                     columns =['File', 'Transcription', 'Result', 'WER'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28058cb3",
   "metadata": {},
   "source": [
    "### Spanish Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc6f0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def Spanish():\n",
    "    scorer = \"Models/kenlm_es.scorer\"\n",
    "    model = \"Models/output_graph_es.pbmm\"\n",
    "    result = []\n",
    "    WER = []\n",
    "    Total = []\n",
    "    \n",
    "    ds = Model(model)\n",
    "    ds.enableExternalScorer(scorer)\n",
    "    desired_sample_rate = ds.sampleRate()\n",
    "    # For Loop to iterate every wav file \n",
    "    for i in range(0,3):\n",
    "        audio = lr.load(audio_fileES[i], sr=desired_sample_rate)[0]\n",
    "        audio = (audio * 32767).astype(np.int16)  # scale from -1 to 1 to +/-32767\n",
    "        res = ds.stt(audio)\n",
    "        result.append(res)\n",
    "    \n",
    "    # Start noise reduction ALGORITHM\n",
    "    for i in range(3,5):\n",
    "        #Get Filename 'what_time_es.wav', 'where_es.wav'\n",
    "        filepath = audio_fileES[i]\n",
    "        filename = os.path.basename(filepath)#what_time_es.wav\n",
    "        first = 'NoiseRd'\n",
    "        last = filename\n",
    "        Newfilename = \"{f}_{l}\".format(f=first, l=last) #eg. NoiseRd_what_time_es.wav\n",
    "        #Get NEW variable filename\n",
    "        base_dir = r\"./Ex4_audio_files/ES/Noise_reduced\"\n",
    "        filename = Newfilename\n",
    "        NewPath = os.path.join(base_dir, filename) # Gives the full filepath\n",
    "        \n",
    "        # Start noise reduction\n",
    "        rate, data = wavfile.read(audio_fileES[i])\n",
    "        # perform noise reduction\n",
    "        reduced_noise = nr.reduce_noise(y=data, sr=rate) \n",
    "        wavfile.write(NewPath, rate, reduced_noise)\n",
    "        \n",
    "    # Start Low-pass Filter    \n",
    "    wave = read_wave('Ex4_audio_files/ES/Noise_reduced/NoiseRd_what_time_es.wav')\n",
    "    wave2 = read_wave('Ex4_audio_files/ES/Noise_reduced/NoiseRd_where_es.wav')\n",
    "    spectrum = wave.make_spectrum()\n",
    "    spectrum2 = wave2.make_spectrum()\n",
    "    spectrum2.low_pass(4000)\n",
    "    spectrum.low_pass(4000)\n",
    "    filtered_wave = spectrum.make_wave()\n",
    "    filtered_wave2 = spectrum2.make_wave()\n",
    "    filtered_wave.unbias()\n",
    "    filtered_wave.normalize()\n",
    "    filtered_wave.write(\"Ex4_audio_files/ES/Noise_reduced/Filtered/Filtered_what_time_es.wav\")\n",
    "    filtered_wave2.write(\"Ex4_audio_files/ES/Noise_reduced/Filtered/Filtered_where_es.wav\")\n",
    "    #Read the new Files from filtered folder and append New result\n",
    "    for i in range(len(Filtered_ES)):\n",
    "        # Add the proceesed audio to result list\n",
    "        New_filered_audio = lr.load(Filtered_ES[i], sr=desired_sample_rate)[0]\n",
    "        New_filered_audio = (New_filered_audio * 32767).astype(np.int16)  # scale from -1 to 1 to +/-32767\n",
    "        New_res = ds.stt(New_filered_audio)\n",
    "        result.append(New_res)\n",
    "        \n",
    "    audioFiles = ['checkin_es.wav', 'parents_es.wav', 'suitcase_es.wav', 'what_time_es.wav', \n",
    "                   'where_es.wav']\n",
    "    transcription = ['donde estan los mostradores', 'he perdido a mis padres', 'por favor he perdido mi maleta', \n",
    "                'a que hora es mi avion', 'donde estan los restaurantes y las tiendas']\n",
    "    #Loop to compare each element in result with transcription list\n",
    "    for i in range(0, len(result)):\n",
    "        #Use wer() to find error rate\n",
    "        error = wer(result[i],transcription[i])\n",
    "        #Convert into percentage\n",
    "        percentage = str(round(error*100)) + '%'\n",
    "        avg = round(error*100)\n",
    "        WER.append(percentage)\n",
    "        #Get Total error rate\n",
    "        Total.append(avg)\n",
    "    # Creating an average WER\n",
    "    Sum = sum(Total)\n",
    "    AvgWER = str(round((Sum / len(Total)), 2))  + '%'\n",
    "    print(\"The Average WER is: \"+ AvgWER)\n",
    "    #Global variable to call it outside of function\n",
    "    global df\n",
    "    # Calling DataFrame constructor on list\n",
    "    df = pd.DataFrame(list(zip(audioFiles, transcription, result, WER)),\n",
    "                     columns =['Files', 'Transcription', 'Result','WER'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee606825",
   "metadata": {},
   "source": [
    "The above ^^^ method have successfully reduced the WER from 47% average to 32.8% by **reducing the background noise** first and then use that audio file and pass through a **low-pass filter.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcd16f",
   "metadata": {},
   "source": [
    "### Italian Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1dd713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def Italian():\n",
    "    scorer = \"Models/kenlm_it.scorer\"\n",
    "    model = \"Models/output_graph_it.pbmm\"\n",
    "    result = []\n",
    "    WER = []\n",
    "    Total = []\n",
    "    \n",
    "    ds = Model(model)\n",
    "    ds.enableExternalScorer(scorer)\n",
    "    desired_sample_rate = ds.sampleRate()\n",
    "    # create 1 sec of silence audio segment\n",
    "    one_sec_segment = AudioSegment.silent(duration=1000)  #duration in milliseconds\n",
    "    # For Loop to iterate every wav file \n",
    "    for i in range(0,len(audio_fileIT)):\n",
    "        ###### ADDING 1second silence in front #########\n",
    "        #Load every IT audio and assign variable\n",
    "        loadAudio = audio_fileIT[i]\n",
    "        #read wav file to an audio segment\n",
    "        SegmentLoad = AudioSegment.from_wav(loadAudio)\n",
    "        #Add above two audio segments    \n",
    "        audio_Out= one_sec_segment + SegmentLoad\n",
    "        \n",
    "        #Get Filename 'what_time_it.wav', 'where_it.wav'\n",
    "        filepath = audio_fileIT[i]\n",
    "        filename = os.path.basename(filepath)#what_time_it.wav\n",
    "        first = 'Silenced'\n",
    "        last = filename\n",
    "        Newfilename = \"{f}_{l}\".format(f=first, l=last) #eg. SilenceAdded_what_time_it.wav\n",
    "        #Get NEW variable filename\n",
    "        base_dir = r\"./Ex4_audio_files/IT/SilenceAdded\"\n",
    "        filename = Newfilename\n",
    "        NewPath = os.path.join(base_dir, filename) # Gives the full filepath\n",
    "        #Save modified audio\n",
    "        audio_Out.export(NewPath, format=\"wav\")\n",
    "        print(filename)\n",
    "        \n",
    "    for i in range(0,len(NewAudio_IT)):\n",
    "        audio = lr.load(NewAudio_IT[i], sr=desired_sample_rate)[0]\n",
    "        audio = (audio * 32767).astype(np.int16)  # scale from -1 to 1 to +/-32767\n",
    "        res = ds.stt(audio)\n",
    "        result.append(res)\n",
    "    audioFiles = ['checkin_it.wav', 'parents_it.wav', 'suitcase_it.wav', 'what_time_it.wav',\n",
    "                   'where_it.wav']\n",
    "    transcription = ['dove e il bancone','ho perso i miei genitori','per favore ho perso la mia valigia',\n",
    "                     'a che ora e il mio aereo', 'dove sono i ristoranti e i negozi']\n",
    "    #Loop to compare each element in result with transcription list\n",
    "    for i in range(0, len(result)):\n",
    "        #Use wer() to find error rate\n",
    "        error = wer(result[i],transcription[i])\n",
    "        #Convert into percentage\n",
    "        percentage = str(round(error*100)) + '%'\n",
    "        avg = round(error*100)\n",
    "        #Print percentage for debugging\n",
    "        #print(percentage)\n",
    "        WER.append(percentage)\n",
    "        #Get Total error rate\n",
    "        Total.append(avg)\n",
    "        #Print comparison strings\n",
    "        #print(result[i],transcription[i])\n",
    "    # Creating an average WER\n",
    "    Sum = sum(Total)\n",
    "    AvgWER = str(round((Sum / len(Total)), 2))  + '%'\n",
    "    print(\"The Average WER is: \"+ AvgWER)\n",
    "    #Global variable to call it outside of function\n",
    "    global df\n",
    "    # Calling DataFrame constructor on list\n",
    "    df = pd.DataFrame(list(zip(audioFiles, transcription, result, WER)),\n",
    "                     columns =['Files', 'Transcription', 'Result', 'WER'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb552f",
   "metadata": {},
   "source": [
    "#### Spanish Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8558cf",
   "metadata": {},
   "source": [
    "Using the wav file with the highest WER \"what_time_es.wav\" of 165% as test subject for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dc1cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer = \"Models/kenlm_es.scorer\"\n",
    "# model = \"Models/output_graph_es.pbmm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e080bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = Model(model)\n",
    "# ds.enableExternalScorer(scorer)\n",
    "# desired_sample_rate =ds.sampleRate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76e3b8",
   "metadata": {},
   "source": [
    "Using a juypter library 'noisereduce' to remove background noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0d57c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.io import wavfile\n",
    "# import noisereduce as nr\n",
    "# # load data\n",
    "# rate, data = wavfile.read(\"Ex4_audio_files/ES/what_time_es.wav\")\n",
    "# # perform noise reduction\n",
    "# reduced_noise = nr.reduce_noise(y=data, sr=rate) \n",
    "# wavfile.write(\"Ex4_audio_files/ES/Noise_reduced/Testnd_what_time_es.wav\", rate, reduced_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3957321",
   "metadata": {},
   "source": [
    "Using a low pass filter to filter out noise above 4kHz of human speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07a373c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wave = read_wave('Ex4_audio_files/ES/Noise_reduced/NoiseRd_what_time_es.wav')\n",
    "# spectrum = wave.make_spectrum()\n",
    "# spectrum.low_pass(4000)\n",
    "# wave.make_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7799b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_wave = spectrum.make_wave()\n",
    "# filtered_wave.unbias()\n",
    "# filtered_wave.normalize()\n",
    "# filtered_wave.make_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8987adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_wave.write(\"Ex4_audio_files/ES/Noise_reduced/Filtered/filtered.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa5961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file = \"Ex4_audio_files/ES/Noise_reduced/Filtered/filtered.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b9f5b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = lr.load(audio_file, sr=desired_sample_rate)[0]\n",
    "# audio = (audio * 32767).astype(np.int16)  # scale from -1 to 1 to +/-32767\n",
    "# res = ds.stt(audio)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b4fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription = ['a que hora es mi avion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e084c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = wer(res,transcription)\n",
    "# #Convert into percentage\n",
    "# percentage = str(round(error*100)) + '%'\n",
    "# print(\"New WER is: \" + percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fe3d7",
   "metadata": {},
   "source": [
    "#### New WER is: 125%\n",
    "The WER has been successfully lowered from 165 to 125, therefore the algorithm works in improving WER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411062ac",
   "metadata": {},
   "source": [
    "#### Italian Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89532e0",
   "metadata": {},
   "source": [
    "Using the wav file with the highest WER \"what_time_it.wav\" of 700% as test subject for this experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aa976d",
   "metadata": {},
   "source": [
    "Adding 1 second of silence before before the audio might give the algorithm more time to recognize the speech and WER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35b563a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pydub\n",
    "# from pydub import AudioSegment\n",
    "# from pydub.playback import play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44a39162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scorer = \"Models/kenlm_it.scorer\"\n",
    "# model = \"Models/output_graph_it.pbmm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e07a7aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = []\n",
    "# WER = []\n",
    "# Total = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6278b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = Model(model)\n",
    "# ds.enableExternalScorer(scorer)\n",
    "# desired_sample_rate = ds.sampleRate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff5df471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadAudio = \"Ex4_audio_files/IT/what_time_it.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cc34d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_file = \"Ex4_audio_files/IT/SilenceAdded/test.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b070ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create 1 sec of silence audio segment\n",
    "# one_sec_segment = AudioSegment.silent(duration=1000)  #duration in milliseconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27d9a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #read wav file to an audio segment\n",
    "# Test = AudioSegment.from_wav(loadAudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f063a728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Add above two audio segments    \n",
    "# audio_Out= one_sec_segment + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adfe33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Either save modified audio\n",
    "# audio_Out.export(audio_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07164cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio = lr.load(audio_file, sr=desired_sample_rate)[0]\n",
    "# audio = (audio * 32767).astype(np.int16)  # scale from -1 to 1 to +/-32767\n",
    "# res = ds.stt(audio)\n",
    "# print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "693bb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription = ['a che ora e il mio aereo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d226a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = wer(res,transcription)\n",
    "# #Convert into percentage\n",
    "# percentage = str(round(error*100)) + '%'\n",
    "# print(\"New WER is: \" + percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149f57c",
   "metadata": {},
   "source": [
    "The algorithm has succesfully reduced the WER **from 700% to 33%!** , this method is great in improving the speech algorithm and will be updated in the Italian function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
